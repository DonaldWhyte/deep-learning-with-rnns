<!doctype html>
<html lang="en">

  <head>
    <meta charset="utf-8">

    <title>Deep Learning with Recurrent Neural Networks</title>

    <meta name="description" content="Presentation briefly introducing deep learning and how to apply a specific subset of deep learning, recurrent neural networks, to solve real world problems.">
    <meta name="author" content="Alejandro Saucedo and Donald Whyte">

    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">

    <link rel="stylesheet" href="css/reveal.css">
    <link rel="stylesheet" href="css/theme/white.css" id="theme">
    <link rel="stylesheet" href="css/custom.css">

    <!-- Code syntax highlighting -->
    <link rel="stylesheet" href="lib/css/zenburn.css">

    <!-- Printing and PDF exports -->
    <script>
      var link = document.createElement( 'link' );
      link.rel = 'stylesheet';
      link.type = 'text/css';
      link.href = window.location.search.match( /print-pdf/gi )
        ? 'css/print/pdf.css' : 'css/print/paper.css';
      document.getElementsByTagName( 'head' )[0].appendChild( link );
    </script>

    <!--[if lt IE 9]>
    <script src="lib/js/html5shiv.js"></script>
    <![endif]-->
  </head>

  <body>

    <div class="reveal">

      <div class="slides">
        <section>
          <section>
            <h2>Deep Learning with Recurrent Neural Networks</h2>
            <h4>In Python</h4>
            <p>
                <a href="http://donaldwhyte.co.uk">Alejandro Saucedo</a>
                / <a href="http://twitter.com/axsauze">@axsauze</a><br/>
                <a href="http://donaldwhyte.co.uk">Donald Whyte</a>
                / <a href="http://twitter.com/donald_whyte">@donald_whyte</a>
              <br />
            </p>
            <p>

            </p>
          </section>

          <section data-markdown>
            By the end of this talk...

            Build a TODO.
          </section>

          <section data-markdown>
            ## Outline

            * TODO
          </section>
        </section>

        <section>
          <section data-markdown>
            ## 1. Supervised Learning
          </section>

          <section data-markdown>
            Use labeled historical data to predict future outcomes
          </section>

          <section data-markdown>
            Given some input data, predict the correct output

            ![shapes](images/shapes.svg)

            What **features** of the input tell us about the output?
          </section>

          <section data-notes="
Raw input data in the shape example before would be all of the pixels that make
up a shape, or even the raw binary data that makes up the image.
">
            <h3>Feature Space</h3>

            <ul>
              <li>A feature is some property that describes raw input data</li>
              <li>
                Input is represented as a vector in
                <strong>feature space</strong>
              </li>
              <li>2 features = 2D vector = 2D space</li>
            </ul>

            <center>
              <div id="shape-plot"
                   style="width: 500px; height: 400px; margin-top: 32px">
              </div>
            </center>
          </section>

          <section data-markdown data-notes="
Raw input data in the shape example before would be all of the pixels that make
up a shape, or even the raw binary data that makes up the image.

Other examples of raw inputs include each character in a document, each byte in
a file, every sample frequency in audio.

These inputs are highly complex and noisy, which makes it incredibly difficult
to identity patterns and infer greater meaning from the data.

So we abstract away the complexity using feature vectors, which significantly
reduce the dimensionality of the data.

* Added benefits:
  - remove redundant information
  - decreases time it takes to learn a good model
  - comprehensible by research (REFER TO PREVIOUS SLIDE)
">
            ### Why Use Feature Space?

            ![feature-extractor](images/feature-extractor.svg)

            * Could simply use raw binary data as input
            * Raw inputs are complex and noisy
            * Abstract the complexity away by using features
          </section>

          <section data-notes="
Supervised leanring depends on use having a training dataset, that has both
the input features and the *known* outputs of those feature vectors.

The training data is used to find a function, or model, that effectively
discriminates between your inputs.

The model cuts the feature space into regions, where each region
corresponds to an output class.

In the example here, we see that the model segments the feature space into
our two output classes -- triangles and squares.

Once we have a trained model, we use it to classify new, unseen data by
transforming it into a feature vector, mapping it to feature space, and
chekcing which region the vector is mapped to.
">
            <div class="left-col">
              <ul>
                <li>Training data is used to produce a model</li>
                <li> f(x&#x0304;) = mx&#x0304; + c </li>
                <li>Model divides feature space into segments</li>
                <li>Each segment corresponds to one <strong>output class</strong></li>
              </ul>
            </div>

            <div class="right-col">
              <center>
                <div id="shape-plot-discriminant" style="width: 450px"></div>
              </center>
            </div>

            <div class="clear-col"></div>

            <p>
              Use trained model to predict outcome of new, unseen inputs
            </p>
          </section>

          <section data-notes="
Now in reality, your data might not be linearly seperable, so we might have to
use a more complex model to correctly discriminate between the different output
classes.

Of course, we need to be careful our models don't overfit our input training
data, otherwise it will fail to correctly classify new, unseen data points.

We can see on the diagram on the right, there are many unseen square instances
that have been incorrectly classified as a triangle. The two triangles near them
might just be outliers, but because the model was trained on a small training
dataset, the feature space looked like it had a different structure.
">
            <h3>Choosing a Suitable Model</h3>

            <div class="left-col">
              <center>
                <div id="shape-plot-complex" style="width: 450px"></div>
              </center>
            </div>
            <div class="right-col fragment" data-fragment="1">
              <center>
                <div id="shape-plot-overfitting" style="width: 450px"></div>
              </center>
            </div>
          </section>
        </section>

        <section data-notes="
TODO: finish this section

REALLY think about how to make it concise.

TODO: think of good example to use

* straight line equation (as in the last section)
* say we want to model non-linear
* combine equations into a system of equations, say we need to learn whole matrix
* turn single straight line into a perceptron
* turn whole set of equations into network
* high-level explanation of backprop to learn the weights
">
          <section data-markdown>
            ## 2. Neural Networks
          </section>

          <section data-markdown>
            TODO
          </section>

          <section data-markdown>
            TODO
          </section>
        </section>

        <section>
          <section data-markdown data-notes="
Good learning resources:

https://medium.com/@camrongodbout/recurrent-neural-networks-for-beginners-7aca4e933b82
          ">
            ## 3. Recurrent Neural Networks
          </section>

          <section data-markdown>
            TODO: basic definition of RNN w/ loop unrolling
            ![TODO](images/RNN-rolled.png)
          </section>

          <section data-markdown>
            TODO: what these can be used for (sequential data, things that need
            memory of past inputs for context)
          </section>

          <section data-markdown>
            TODO: limitations -- in theory can remember all past inputs but in
            reality this doesn't work with vanilla RNNs
          </section>

          <section data-markdown>
            TODO: briely mention LSTMs, but don't go into it deal
          </section>
        </section>

        <section>
          <section data-markdown>
            ## 4. RNNs in Python
          </section>

          <section data-markdown data-notes="
Allows user to write symbolic mathematical expressions, then automatically generates their derivatives, saving the user from having to code gradients or backpropagation. These symbolic expressions are automatically compiled to CUDA code for a fast, on-the-GPU implementation.

Theano: The reference deep-learning library for Python with an API largely compatible with the popular NumPy library.
">
            * Libraries that build graph-based math expressions
            * Automatically generates the derivates of each node
            * Builds the system of equations to learn model parameters for you
          </section>

          <section data-markdown>
            TODO: basic diagram for this

            Low-level compute graph libraries:

            * Theano
            * Tensorflow (Google)
            * Caffe (Berkley)

            High-level libraries:

            * Keras
            * Sonnet (DeepMind)
          </section>

          <section data-markdown>
            Let's use *Keras*.
          </section>

          <section data-markdown>
            * Built on top of Tensorflow
            * Can build very complex networks quickly
            * Easy to extend if required
            * Built-in support for LSTM nodes
          </section>

          <section data-markdown data-notes="
Keras can use many compute backends, such as TensorFlow, Theano and CNTK.
">
            ### Installation

            Keras can use many compute backends.

            Let's use TensorFlow.

            ```bash
            pip3 install tensorflow
            pip3 install keras
            ```
          </section>

          <section data-markdown>
            ### TODO

            TODO
          </section>

          <section data-markdown data-notes="
Source: https://keras.io/visualization/
">
            Visualise a Keras model:

            ```bash
            # Install required dependencies to generate graphs
            brew install graphviz
            pip3 install pydot
            ```

            ```python
            from keras.utils import plot_model
            plot_model(model, to_file='model.svg')
            ```

            <img src="TODO: plotted graph" />
          </section>
        </section>

      </div>

    </div>

    <script src="lib/js/head.min.js"></script>
    <script src="js/reveal.js"></script>

    <!-- Custom JS libraries -->
    <script src="lib/js/jquery-3.2.1.min.js"></script>
    <script src="lib/js/highcharts.js"></script>

    <!-- Reveal initialisation -->
    <script>
      Reveal.initialize({
        controls: true,
        progress: true,
        history: true,
        center: true,

        transition: 'none', // none/fade/slide/convex/concave/zoom

        // Optional reveal.js plugins
        dependencies: [
          { src: 'lib/js/classList.js', condition: function() { return !document.body.classList; } },
          { src: 'plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
          { src: 'plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
          { src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } },
          { src: 'plugin/zoom-js/zoom.js', async: true },
          { src: 'plugin/notes/notes.js', async: true },
          {
            src: 'plugin/external/external.js',
            condition: function() {
              return !!document.querySelector( '[data-external]' );
            }
          },
        ]
      });

      // Charts construction

      function loadChartEvent(event) {
        // Remove Highcharts.com marker
        $("text:contains('Highcharts.com')").remove();
      }

      var shapeChart = {
        chart: {
          type: 'scatter',
          zoomType: 'xy',
          backgroundColor: 'rgba(0, 0, 0, 0)',
          events: {
            load: loadChartEvent
          }
        },
        title: {
          text: ''
        },
        xAxis: {
          title: {
            text: 'Area',
            style: {
              fontSize: '24px',
              color: 'black',
              'font-weight': 'strong'
            }
          },
          labels: {
            style: {
              color: 'black',
              'font-weight': 'strong',
              'font-size': '14px'
            }
          }
        },
        yAxis: {
          title: {
            text: 'Perimeter',
            style: {
              fontSize: '24px',
              color: 'black'
            }
          },
          labels: {
            style: {
              color: 'black',
              'font-weight': 'strong',
              'font-size': '14px'
            }
          }
        },
        legend: {
          enabled: false
        },
        tooltip: {
          enabled: false
        },
        exporting: {
          enabled: false
        },
        plotOptions: {
          scatter: {
            marker: {
              radius: 10,
              states: {
                hover: {
                  enabled: true,
                  lineColor: '#000'
                }
              }
            }
          }
        },
        series: [
          {
            name: 'Square',
            marker: {
              symbol: 'square'
            },
            color: 'rgba(223, 83, 83, 1)',
            data: [
              [3.7, 0.9], [3.9, 1.7],
              [3.9, 0.9], [4.2, 1.2],
              [3.5, 1.4], [3.85, 1.3],
              [3.4, 1.0], [3.7, 1.25]
            ]
          }, {
            name: 'Triangle',
            marker: {
              symbol: 'triangle'
            },
            color: 'rgba(119, 152, 191, 1)',
            data: [
              [2.75, 0.18], [3.2, 0.22],
              [4.2, 0.65], [4.1, 0.20],
              [3.5, 0.4], [4.0, 0.24],
              [4.15, 0.5], [3.8, 0.5],
              [2.8, 0.6], [3.8, 0.5],
              [3.0, 0.8], [2.7, 1.4],
              [3.1, 0.5], [2.8, 1.3],
              [2.7, 1.1], [2.8, 0.9],
              [3.15, 1.25], [3.5, 1.9]
            ]
          }
        ]
      };

      var shapeChartWithDiscriminant = jQuery.extend(true, {}, shapeChart);
      shapeChartWithDiscriminant["series"].push({
        type: 'line',
        name: 'Discriminant',
        data: [[4.2, 0.1], [2.8, 1.9]],
        marker: {
          enabled: false
        },
        enableMouseTracking: false,
        showInLegend: false,
        lineWidth: 5,
        lineColor: 'black'
      });

      var shapeChartComplex = jQuery.extend(true, {}, shapeChart);
      shapeChartComplex['series'].push({
        type: 'spline',
        name: 'Discriminant',
        data: [[3.65, 1.9], [3.25, 1.1], [3.25, 0.95], [3.5, 0.65], [4.2, 0.8]],
        marker: {
          enabled: false
        },
        enableMouseTracking: false,
        showInLegend: false,
        lineWidth: 5,
        lineColor: 'black'
      });

      var shapeChartOverfitting = jQuery.extend(true, {}, shapeChartComplex);
      shapeChartOverfitting['series'].push({
        name: 'Square-Wrong',
        marker: {
          symbol: 'square'
        },
        color: 'purple',
        showInLegend: false,
        data: [ [3.30, 1.8], [3.15, 1.75], [3.35, 1.55], [3.05, 1.55], [3.25, 1.6] ]
      });

      $(function () {
        $('#shape-plot').highcharts(shapeChart);
        $('#shape-plot-discriminant').highcharts(shapeChartWithDiscriminant);
        $('#shape-plot-complex').highcharts(shapeChartComplex);
        $('#shape-plot-overfitting').highcharts(shapeChartOverfitting);
      });
    </script>

  </body>
</html>
